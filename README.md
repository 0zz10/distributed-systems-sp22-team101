# Lab 7 - Adding Persistence

Created: March 1, 2022 12:39 PM
Date: March 11, 2022
References: https://github.com/gortonator/bsds-6650/blob/master/labs/lab-5.md
https://github.com/gortonator/bsds-6650/blob/master/labs/lab-7.md
https://github.com/gortonator/bsds-6650/blob/master/assignments-2021/Assignment-3.md
https://github.com/gortonator/bsds-6650/blob/master/labs/lab-8.md
Tags: Circuit Breaker, Database Design, JDBC, MySQL

# Overview

*****Please NOTE!  This will be done in your new Milestone 2 Teams!*****

The main aim of this lab is to (finally!) persist the tuples generated by the your client!  Now things get really interesting, and you might want to have a look at this CQRS design pattern for some inspiration ([https://docs.aws.amazon.com/prescriptive-guidance/latest/modernization-data-persistence/cqrs-pattern.html](https://docs.aws.amazon.com/prescriptive-guidance/latest/modernization-data-persistence/cqrs-pattern.html)!

It’s likely that the AWS restrictions on the number of instances you can start will mean you might not be able to use the load balancer. Feel free to increase capacity of servers - just report what you used for gathering results sand **watch your $$s**!

# Scaling Relational Databases

![[https://www.youtube.com/watch?v=uynmnvmzAgs&list=PLLGiwLi4Z63sQdoptiqqLzHTgBHBK83ed&index=16](https://www.youtube.com/watch?v=uynmnvmzAgs&list=PLLGiwLi4Z63sQdoptiqqLzHTgBHBK83ed&index=16)](Lab%207%20-%20Ad%207a431/Untitled.png)

[https://www.youtube.com/watch?v=uynmnvmzAgs&list=PLLGiwLi4Z63sQdoptiqqLzHTgBHBK83ed&index=16](https://www.youtube.com/watch?v=uynmnvmzAgs&list=PLLGiwLi4Z63sQdoptiqqLzHTgBHBK83ed&index=16)

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%201.png)

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%202.png)

![shared everything architecture](Lab%207%20-%20Ad%207a431/Untitled%203.png)

shared everything architecture

![shared nothing architecture](Lab%207%20-%20Ad%207a431/Untitled%204.png)

shared nothing architecture

![shard lookup](Lab%207%20-%20Ad%207a431/Untitled%205.png)

shard lookup

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%206.png)

![Facebook - custom graph database - TAO](Lab%207%20-%20Ad%207a431/Untitled%207.png)

Facebook - custom graph database - TAO

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%208.png)

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%209.png)

![Database Landscape](Lab%207%20-%20Ad%207a431/Untitled%2010.png)

Database Landscape

# **Week 7- Microservices**

[https://northeastern.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=80e8535b-1f86-4c0c-b4e6-ab9100dda93c](https://northeastern.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=80e8535b-1f86-4c0c-b4e6-ab9100dda93c)

![uber has monolithic architecture → moved to more modern architecture](Lab%207%20-%20Ad%207a431/Untitled%2011.png)

uber has monolithic architecture → moved to more modern architecture

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2012.png)

- Monolithic SOA: large codebase, hard to develop and test

![fine-grained services](Lab%207%20-%20Ad%207a431/Untitled%2013.png)

fine-grained services

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2014.png)

# ****Getting Started: Connecting Tomcat Servlet to MySQL using JDBC****

In this lab, your will be able to add JDBC driver to your project, so that your Java project can access the MySQL database, locally or remotely.

## **Step 1: Add JDBC driver for MySQL and DB Connection Pooling library to your project**

Add the following to the `<dependencies>` tag of your `pom.xml` and wait for your IDE to resolve dependencies.

```xml
<!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->
<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <version>8.0.18</version>
</dependency>

<!-- https://mvnrepository.com/artifact/org.apache.commons/commons-dbcp2 -->
<dependency>
    <groupId>org.apache.commons</groupId>
    <artifactId>commons-dbcp2</artifactId>
    <version>2.7.0</version>
</dependency>
```

## Step 2: Set up DB connection manager

### System.getProperty(”pname”)

Because the code above contains very sensitive information such as public database server IP and port, and the DB access credentials, you should NEVER hard code those info in your code which will be PUBLIC on GitHub. Instead, [store them as system properties](https://stackoverflow.com/a/16566920/3949193) in `TOMCAT_HOME/conf/catalina.properties`, and retrieve them using

```java
System.getProperty("MySQL_IP_ADDRESS")
```

in your Java code.

![/usr/local/apache-tomcat-9.0.44/conf/catalina.properties](Lab%207%20-%20Ad%207a431/Untitled%2015.png)

/usr/local/apache-tomcat-9.0.44/conf/catalina.properties

### Change `/usr/share/tomcat/conf/catalina.properties` at tomcat on EC2

```bash
cd Downloads
ssh -i labsuser.pem [ec2-user@107.21.172.149](mailto:ec2-user@107.21.172.149)
```

```bash
cd /usr/share/tomcat
sudo chmod -R 777 conf/
cd conf
vim catalina.properties
```

[https://vim.rtorr.com/](https://vim.rtorr.com/)

```bash
RABBITMQ_HOST=
RABBITMQ_USERNAME=
RABBITMQ_PASSWORD=
MySQL_IP_ADDRESS=
MySQL_PORT=3306
DB_USERNAME=admin
DB_PASSWORD=
```

The `System` class maintains a `Properties` object that describes the configuration of the current working environment. * 注：这里的system，系统指的是 JRE (runtime)system，不是指 OS。

[如何配置JVM系统属性及获取方式System.getProperty("pname")-阿里云开发者社区](https://developer.aliyun.com/article/330544)

java -D 配置系统属性：`java -Dkey=value`

**功能解析**`java -D=value`官网解释：    Set a system property value. If value is a string that contains spaces, you must enclose the string in double quotes:在虚拟机的系统属性中设置属性名/值对，运行在此虚拟机上的应用程序可用：`System.getProperty("属性名")`

得到value的值。如果value中有空格，则需要用双引号将该值括起来，如：-Dname=”kazaf f”。该参数通常用于设置系统级全局变量值，如配置文件路径，保证该属性在程序中任何地方都可访问。

[System Properties](https://docs.oracle.com/javase/tutorial/essential/environment/sysprop.html)

### **Create and Connect to a MySQL Database**

[https://www.notion.so/zhenjiezhou/Lab-1-Foundational-Services-bf14f1604e2344a68c35e46d4923933e#be15dc117d2f41ebbd7b81916a32cf4a](https://www.notion.so/Lab-1-Foundational-Services-bf14f1604e2344a68c35e46d4923933e)

With JDBC driver downloaded, we are able to let our Java program talk to MySQL database. So next we will create such connection manager class to establish connections between your project and MySQL database.

```java
import org.apache.commons.dbcp2.*;

public class DBCPDataSource {
    private static BasicDataSource dataSource;

    // NEVER store sensitive information below in plain text!
    private static final String HOST_NAME = System.getProperty("MySQL_IP_ADDRESS");
    private static final String PORT = System.getProperty("MySQL_PORT");
    private static final String DATABASE = "LiftRides";
    private static final String USERNAME = System.getProperty("DB_USERNAME");
    private static final String PASSWORD = System.getProperty("DB_PASSWORD");

    static {
        // https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-jdbc-url-format.html
        dataSource = new BasicDataSource();
        try {
            Class.forName("com.mysql.cj.jdbc.Driver");
        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        }
        String url = String.format("jdbc:mysql://%s:%s/%s?serverTimezone=UTC", HOST_NAME, PORT, DATABASE);
        dataSource.setUrl(url);
        dataSource.setUsername(USERNAME);
        dataSource.setPassword(PASSWORD);
        dataSource.setInitialSize(10);
        dataSource.setMaxTotal(60);
    }

    public static BasicDataSource getDataSource() {
        return dataSource;
    }
}
```

> java.sql.SQLException: Cannot create PoolableConnectionFactory (Unknown database '`LiftRides`')
> 

[Adding an Amazon RDS DB instance to your Java application environment](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/java-rds.html)

### Make sure database and table exists before you call DAO

Connect RDS MySQL instance at `MySQL Workbench`

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2016.png)

### Create Database and Table in SQL Query

```sql
CREATE DATABASE LiftRides;

CREATE TABLE `LiftRides`.`LiftRides` (
  `recordId` INT NOT NULL AUTO_INCREMENT,
  PRIMARY KEY (`recordId`),
  `skierId` INT NOT NULL,
  `resortId` INT NULL,
  `seasonId` INT NULL,
  `dayId` INT NULL,
  `time` INT NULL,
  `waitTime` INT NULL,
  `liftID` INT NULL);
```

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2017.png)

DBC uses a connection string in the following format:

```
jdbc:*driver*://*hostname:port*/*dbName*?user=*userName*&password=*password*
```

The following are example driver names:

- `mysql` for MySQL
- `postgresql` for PostgreSQL
- `oracle:thin` for Oracle Thin
- `oracle:oci` for Oracle OCI
- `oracle:oci8` for Oracle OCI 8
- `oracle:kprb` for Oracle KPRB
- `sqlserver` for SQL Server

There are a lot of parameters available to [configure the DBCP](https://tomcat.apache.org/tomcat-9.0-doc/jndi-datasource-examples-howto.html#Database_Connection_Pool_(DBCP_2)_Configurations). Do read the documents and try to achieve the best performance by playing around with these params.

## Step 3: Create a [DAO layer](https://en.wikipedia.org/wiki/Data_access_object) between your Servlets and DB

Below is an example DAO class with a record insertion operation. Your code may vary depending on your DB schema design.

```java
package com.bsds.group101.server;

import org.apache.commons.dbcp2.BasicDataSource;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class LiftRideDao {
  private static BasicDataSource dataSource;

  public LiftRideDao() {
    dataSource = DBCPDataSource.getDataSource();
  }

  // Make sure database and table exists before you call this data insertion
  public void createLiftRide(LiftRide newLiftRide) {
    Connection conn = null;
    PreparedStatement preparedStatement = null;
    String insertQueryStatement =
        "INSERT INTO LiftRides (skierId, resortId, seasonId, dayId, time, waitTime, liftId) "
            + "VALUES (?,?,?,?,?,?,?)";
    try {
      conn = dataSource.getConnection();
      preparedStatement = conn.prepareStatement(insertQueryStatement);
      preparedStatement.setInt(1, newLiftRide.getSkierId());
      preparedStatement.setInt(2, newLiftRide.getResortId());
      preparedStatement.setInt(3, newLiftRide.getSeasonId());
      preparedStatement.setInt(4, newLiftRide.getDayId());
      preparedStatement.setInt(5, newLiftRide.getTime());
      preparedStatement.setInt(6, newLiftRide.getWaitTime());
      preparedStatement.setInt(7, newLiftRide.getLiftId());

      // execute insert SQL statement
      preparedStatement.executeUpdate();

      // log JDBC status
      System.out.println("STORE TO DATABASE AT" + dataSource.getUrl());

    } catch (SQLException e) {
      e.printStackTrace();
    } finally {
      try {
        if (conn != null) {
          conn.close();
        }
        if (preparedStatement != null) {
          preparedStatement.close();
        }
      } catch (SQLException se) {
        se.printStackTrace();
      }
    }
  }
}
```

Usually it is the DAO classes where data is directly accessed from the database, and where POJO is passed into.

After this step is done, you may create a simple test program and check if records can be successfully inserted to your database.

```java
public static void main(String[] args) {
    // pass that object to the DAO layer
    LiftRideDao liftRideDao = new LiftRideDao();
    // construct a LiftRide object with those values
    liftRideDao.createLiftRide(new LiftRide(10, 2, 3, 5, 500, 20, 15));
}
```

## Step 4: Access DB through DAO objects in Servlets

This step should be very straightforward once you have tested that your DAO object works. For example, in `POST` method on `/skiers/{resortID}/seasons/{seasonID}/days/{dayID}/skiers/{skierID}`, in your `doPost` method in the corresponding Servlet, you basically need to

- extract values from URL path params and request body
- construct a `LiftRide` object with those values, and
- pass that object to the DAO layer

of course, don’t forget path validations and some other necessary steps.

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2018.png)

# ****Adding a Skier Microservice!****

In Lab 6, your *consumer* created an in-memory hash map for skier and lift ride information.

Your task is to modify the consumer to persist the results to a database.

You are free to choose any database you like. AWS RDS instances like MySQL, DynamoDB, MongoDB, Redis - all good candidates.

The data model you design in the database should enable queries like:

[SQL GROUP BY Statement](https://www.w3schools.com/sql/sql_groupby.asp)

- “For skier N, how many days have they skied this season?”
- “For skier N, what are the vertical totals for each ski day?”
- “For skier N, show me the lifts they rode on each ski day”

Whatever database you choose, the challenge is to write to the database ideally as fast as you can consume messages from RabbitMQ (or whatever queuing strategy you are using!). This may be challenging based on the EC2 resources you choose, so experiments are required!

Test this configuration by reporting the same results as Lab 6 for 128, 256 clients. Feel free to empty the database between tests. It might help ;)

## Database Options at Consumer

### AWS RDS - MySQL

```sql
CREATE database Consumer;

CREATE TABLE `Consumer`.`LiftRides` (
  `recordId` INT NOT NULL AUTO_INCREMENT,
  PRIMARY KEY (`recordId`),
  `skierId` INT NOT NULL,
  `resortId` INT NULL,
  `seasonId` INT NULL,
  `dayId` INT NULL,
  `time` INT NULL,
  `waitTime` INT NULL,
  `liftID` INT NULL);
```

```sql
SELECT COUNT(recordId)
FROM Consumer.LiftRides;
```

### DynamoDB

[Deploying DynamoDB Locally on Your Computer](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.DownloadingAndRunning.html#apache-maven)

### Using the ElastiCache Cluster Client for Java

[Using the ElastiCache Cluster Client for Java](https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/AutoDiscovery.Using.ModifyApp.Java.html)

The best way is to store the sum as a `separate key`, and to update whenever you add/remove a value from your set/hash/zset.

[What is the best way to do sum/count/groupby in Redis?](https://stackoverflow.com/questions/12474453/what-is-the-best-way-to-do-sum-count-groupby-in-redis)

[amazon-elasticache-redis-and-memcached-java-client-examples/src/com/amazonaws/elasticachedemo at main · aws-samples/amazon-elasticache-redis-and-memcached-java-client-examples](https://github.com/aws-samples/amazon-elasticache-redis-and-memcached-java-client-examples/tree/main/src/com/amazonaws/elasticachedemo)

# ****Experiments****

It’s likely (we hope!) you will see significant backlogs in your queues, servlet and maybe even consumer.  Note: that is AWESOME!

When you do, you have two choices:

1. Increase capacity - this means deploying more than free tier instances. Watch the $$s.
2. Introduce *throttling* - you could do this in the client by introducing a throughput-based *circuit breaker* with exponential backoffs in client POSTs and/or RMQ posts/configuration

## throttling *-* Circuit Breaker Pattern

The circuit breaker can be used in clients to reduce strain on a server that is under heavy load, and to potentially enable a service to provide more stable response times.  A design question you need to think about is whether to use a circuit breaker in

1. the client, which could set a latency threshold and back off if this is exceeded
2. the server, when writing to RabbitMQ

Take a look at your client code and circuit breaker libraries.  The Apache library is probably the easiest to get started with and [these examples](https://commons.apache.org/proper/commons-lang/javadocs/api-3.9/org/apache/commons/lang3/concurrent/EventCountCircuitBreaker.html) might be inspiring, but choose any you’d like to learn.

Can you **DESIGN** a circuit breaker in your assignment to obtain better performance as the load grows?  Note: you do not have implement this yet, but you might want to in Lab 8!  Of course, if you are keen to play with it, you can always do it now! :)

# Deliverables

> Submit your work to Canvas as a pdf document. The document should contain:
> 
1. The URL for your git repo. Create a new folder for your Lab 7 server code
2. A short description with a diagram of your database design and deployment topologies on AWS
3. Test runs (command windows, RMQ management windows showing queue size, send/receive rates) for 128, 256 client threads

## 40runs_20000skiers_128threadsClient_100threadsConsumer

### Statistics at clients

```
total requests: 481531
mean response time: 1496 ms
duration:  5906761ms
Throughput:  81 requests/s
```

```
total requests: 484892
mean response time: 523 ms
duration:  2028686ms
Throughput:  239 requests/s
```

```
total requests: 484856
mean response time: 516 ms
duration:  2001054ms
Throughput:  242 requests/s
```

### 1hr range - Publish@250req/s - Deliver@98req/s

*DBCP + NetworkLoadBalancer associated 4 tomcat servers*

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2019.png)

### 1hr range - Publish@250req/s - Deliver@110req/s

*HikariCP + NetworkLoadBalancer associated 4 tomcat servers*

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2020.png)

### ~7Kth Request - Publish@261req/s - Deliver@97req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2021.png)

### ~~8Kth Request - Publish@251req/s - Deliver@97req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2022.png)

### ~~~8Kth Request - Publish@256req/s - Deliver@116req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2023.png)

### ~~30Kth Request - Publish@250req/s - Deliver@97req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2024.png)

### ~~~45Kth Request - Publish@248req/s - Deliver@116req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2025.png)

### ~~End 484Kth Request, Consumer Asynchronizedly running

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2026.png)

Num of data  **Multi-threaded Consumer Create Data - 494517 req**

```sql
SELECT COUNT(recordId)
FROM Consumer.LiftRides;
```

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2027.png)

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2028.png)

## 40runs_20000skiers_256threadsClient_100threadsConsumer

### Statistics

```
total requests: 
mean response time: 1496 ms
duration:  ms
Throughput:   requests/s
```

### 1hr range - Publish@120req/s - Deliver@10req/s - `SocketTimeoutException`

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2029.png)

### ~~7Kth Request - Publish@253req/s - Deliver@120req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2030.png)

```java
Exception when calling SkiersApi#getSkierDayVertical
io.swagger.client.ApiException: java.net.SocketTimeoutException: timeout
	at io.swagger.client.ApiClient.execute(ApiClient.java:844)
	at io.swagger.client.ApiClient.execute(ApiClient.java:824)
	at io.swagger.client.api.SkiersApi.writeNewLiftRideWithHttpInfo(SkiersApi.java:467)
	at Phase.run(Main.java:104)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: timeout
	at okio.Okio$3.newTimeoutException(Okio.java:207)
	at okio.AsyncTimeout.exit(AsyncTimeout.java:261)
	at okio.AsyncTimeout$2.read(AsyncTimeout.java:215)
	at okio.RealBufferedSource.indexOf(RealBufferedSource.java:306)
	at okio.RealBufferedSource.indexOf(RealBufferedSource.java:300)
	at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:196)
	at com.squareup.okhttp.internal.http.Http1xStream.readResponse(Http1xStream.java:186)
	at com.squareup.okhttp.internal.http.Http1xStream.readResponseHeaders(Http1xStream.java:127)
	at com.squareup.okhttp.internal.http.HttpEngine.readNetworkResponse(HttpEngine.java:737)
	at com.squareup.okhttp.internal.http.HttpEngine.access$200(HttpEngine.java:87)
	at com.squareup.okhttp.internal.http.HttpEngine$NetworkInterceptorChain.proceed(HttpEngine.java:722)
	at com.squareup.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:576)
	at com.squareup.okhttp.Call.getResponse(Call.java:287)
	at com.squareup.okhttp.Call$ApplicationInterceptorChain.proceed(Call.java:243)
	at com.squareup.okhttp.Call.getResponseWithInterceptorChain(Call.java:205)
	at com.squareup.okhttp.Call.execute(Call.java:80)
	at io.swagger.client.ApiClient.execute(ApiClient.java:840)
	... 8 more
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at okio.Okio$2.read(Okio.java:139)
	at okio.AsyncTimeout$2.read(AsyncTimeout.java:211)
	... 22 more
```

### ~~45Kth Request - Publish@250req/s - Deliver@119req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2031.png)

### ~~70Kth Request - Publish@248req/s - Deliver@119req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2032.png)

### ~~210Kth Request - Publish@8.8req/s - Deliver@10req/s

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2033.png)

1. A brief explanation of your mitigation strategy and either a design, or if you get it working go ahead and show results with 128, 256 clients to show their effects. Hopefully positive but negative is fine with good analysis!
    
    
    By default, Tomcat sets `maxThreads`
     to 200, which represents the maximum number of threads allowed to run at any given time. You can also specify values for the following parameters:
    
    ![Datadog. (, 00:00 +  UTC). *Understanding the Tomcat architecture and key performance metrics*. Understanding the Tomcat Architecture and Key Performance Metrics. [https://www.datadoghq.com/blog/tomcat-architecture-and-performance/](https://www.datadoghq.com/blog/tomcat-architecture-and-performance/)](Lab%207%20-%20Ad%207a431/Untitled%2034.png)
    
    Datadog. (, 00:00 +  UTC). *Understanding the Tomcat architecture and key performance metrics*. Understanding the Tomcat Architecture and Key Performance Metrics. [https://www.datadoghq.com/blog/tomcat-architecture-and-performance/](https://www.datadoghq.com/blog/tomcat-architecture-and-performance/)
    
    Upon startup, Tomcat will create threads based on the value set for `minSpareThreads`
     and increase that number based on demand, up to the number of `maxThreads`. If the maximum number of threads is reached, and all threads are busy, the server will only continue to accept a certain number of concurrent connections (as determined by `maxConnections`). 
    
    Once that limit is reached, new connections are placed in a queue (`acceptCount`) to wait for the next available thread. When the number of connections hits `maxConnections` and the queue is full, any additional incoming clients will start receiving `Connection Refused`errors. 
    
    If your server begins generating these errors, you will need to adjust your connectors' thread pool capacity to better accommodate the number of incoming requests.
    

# Troubleshoots

## Restart Tomcat on AWS EC2

[https://medium.com/@shrunk7byadagi/automatically-start-tomcat-on-instance-startup-reboot-in-amazon-ec2-ubuntu-instance-33849a9d9090](https://medium.com/@shrunk7byadagi/automatically-start-tomcat-on-instance-startup-reboot-in-amazon-ec2-ubuntu-instance-33849a9d9090)

### use `systemctl` command

Check status of Tomcat Service:

```bash
$ systemctl status tomcat
```

![Untitled](Lab%207%20-%20Ad%207a431/Untitled%2035.png)

```bash
$ sudo systemctl start tomcat
```

## Manage the RabbitMQ Service

[https://www.rabbitmq.com/install-debian.html#managing-service](https://www.rabbitmq.com/install-debian.html#managing-service)

To start and stop the server, use the `systemctl` tool. The service name is `rabbitmq-server`:

```bash
# stop the local node
$ sudo systemctl stop rabbitmq-server

# start it back
$ sudo systemctl start rabbitmq-server
```

`systemctl status rabbitmq-server` will report service status as observed by systemd (or similar service manager):

```bash
# check on service status as observed by service manager
$ sudo systemctl status rabbitmq-server
```

## Channel error at RabbitMQ: set durable to `true`

```
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=406, reply-text=PRECONDITION_FAILED - inequivalent arg 'durable' for queue 'liftRides' in vhost '/': received 'false' but current is 'true', class-id=50, method-id=10)
```

[https://stackoverflow.com/questions/31762563/issue-in-establishing-connection-with-rabbit-mq](https://stackoverflow.com/questions/31762563/issue-in-establishing-connection-with-rabbit-mq)

### Solution:

1. run you app with consumer durable=true in channel.queueDeclare

let it connect the queue

1. close it.
2. start the producer

![`channel.queueDeclare(QUEUE_NAME, true, false, false, null);`](Lab%207%20-%20Ad%207a431/Untitled%2036.png)

`channel.queueDeclare(QUEUE_NAME, true, false, false, null);`

This is happening since your pre-existing channel on your RabbitMQ server, named `test`, was created with durable set `true`:

```
channel.queueDeclare(QUEUE_NAME, true, false, false, null);
```

You've since changed your code like so:

```
channel.queueDeclare(QUEUE_NAME, false, false, false, null);
```

# References:

## **Addendum: Multithreading and RabbitMQ**

RabbitMQ and multithreading needs a few considerations. Read on ....

The basic abstraction that needs to be operated on by each thread is the channel. This means:

In your servlet (or equivalent if not using a servlet):

1. In the init() method, initialize the connection (this is the socket, so is slow)
2. In the dopost(), create a channel and use that to publish to RabbitMQ. Close it at end of the request.

This should work fine, although the [documentation](https://www.rabbitmq.com/api-guide.html#concurrency) say channels are meant to be long-lived and caution again churn.

So a better solution would be to create a channel pool that shares a bunch of pre-created channels (in .init()) to form a connection pool.

Roll your own is not too hard, but apache commons has a [generic pool implementation](http://commons.apache.org/proper/commons-pool/examples.html) that you could build on. The reading has an example of how to do this.

Another approach to implementing a channel pool would be to use a BlockingQueue. Not too tricky ... give it a try!

On the consumer side, you probably want a multi-threaded consumer that just gets a message and writes to the hash map. In this case you can just create a channel per thread and all should be fine.

There's an excellent write up that describes the complexities of multi-threaded RMQ clients [here](http://moi.vonos.net/bigdata/rabbitmq-threading/)

And [here's](https://github.com/gortonator/bsds-6650/tree/master/code/week-6) some sample code you can work from.

## **Amazon MQ**

[https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/welcome.html](https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/welcome.html)

## **Working with Amazon Simple Queue Service**

[https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/examples-sqs.html](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/examples-sqs.html)

[aws-doc-sdk-examples/SQSExample.java at main · awsdocs/aws-doc-sdk-examples](https://github.com/awsdocs/aws-doc-sdk-examples/blob/main/javav2/example_code/sqs/src/main/java/com/example/sqs/SQSExample.java)

[Sending, receiving, and deleting Amazon Simple Queue Service messages](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/examples-sqs-messages.html)

Sending, receiving, and deleting Amazon Simple Queue Service messages